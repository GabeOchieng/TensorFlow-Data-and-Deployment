{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXdEnmVvXdUa"
   },
   "source": [
    "# Train Your Own Model and Serve It With TensorFlow Serving\n",
    "\n",
    "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSfb9Qd5XdFL"
   },
   "source": [
    "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access. If you want to run it in a local Jupyter notebook, please proceed with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcLTAmF5Xs2T"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%204%20-%20TensorFlow%20Serving/Week%201/Exercises/TFServing_Week1_Exercise.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2Q8bkjeYTl-"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g8r89tTPI-Kb",
    "outputId": "5166252b-6fb7-4b4f-af25-3cb238b8c152"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XGFJmWjrKttn",
    "outputId": "52b66b51-926d-4874-af5a-a3143f31899f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version: 2.2.0-dev20200217\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pq-214o8SNt0"
   },
   "source": [
    "## Import the MNIST Dataset\n",
    "\n",
    "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
    "\n",
    "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7MqDQO0KCaWS",
    "outputId": "703eaea1-6791-4e4b-944f-9e86947dedba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIT-qX0QzLo-"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
    "train_images = train_images / 255.0\n",
    "test_images =  test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIDGu-EEzdKb"
   },
   "source": [
    "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
    "\n",
    "```python\n",
    "train_images.shape: (60000, 28, 28, 1)\n",
    "test_images.shape: (10000, 28, 28, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsIxeG6BzN4t"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Reshape the arrays below.\n",
    "train_images = train_images.reshape((*train_images.shape,1))\n",
    "test_images =  test_images.reshape((*test_images.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aUw8ZxigB1Nx",
    "outputId": "7f551b7d-eff7-419b-bdf8-26b89a48e2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_images.shape: (60000, 28, 28, 1), of float64\n",
      "test_images.shape: (10000, 28, 28, 1), of float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcR0OKbOSj0c"
   },
   "source": [
    "## Look at a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "VQMs4v_oSo9v",
    "outputId": "a09e480d-fedd-4684-98c6-f2a2b240f287"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEKCAYAAADUyyOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ0UlEQVR4nO3dfaxU9Z3H8fdHWytFXFCuyKLx2opRt9lSvSVrtEa34tNqoI1VWUNoJKW6murWrLI0WR+SRtZdNc3uxg0WLVSFylojRldlTV1rdm28sihYs4oGLBThol3xsQr97h9z0PE6c+5lzpk5c/l9XslkZs73PHwz8LnnzHmYo4jAzPZ8e1XdgJl1hsNulgiH3SwRDrtZIhx2s0Q47GaJcNhLJCmG8VhfdZ8AkhZI2lHSvF6T9OMy5pXN7ylJD5cwn/GStmWf+4ll9DaSfabqBvYwxw96fx/wLHBt3bDfd6wbuwn4sOomuoXDXqKIeKr+vaTfA9sGD29G0uciwn8MSiDpz4FvAt8HFlbcTlfwZnxFJC2TtE7SSdlm63vA9ZL2zTY75w0a/6hs+AWDhp8q6XFJb2ePByUdXVKPZ0l6ONtMf0fSGknfk9Tw/42kv5L0iqT3JT0t6WsNxmlbv3XL2Bf4V+B64Ddlznskc9irNR74KbAEOBP4t92ZWNI3gUeAbcBfArOAHuAJSRNL6O8LwMPAt4FzgLuABcDfNRj3dOAS4OqsF4BHJB1eRr/ZH5zhfo//AfABcMswx0+CN+Or9UfA+RHxyK4B2VppSNna9UfAIxFxbt3w/wReAS4H5jWZfFgi4p/r5ivgCWA0tVBfO2j08cBXI+K1bPxfABuA+cB3Suh3B7BzqJ6zrYS/AaZFxI5a2wYOe9XerQ/6bvoT4BDgakn1/47bgaeBk4o2J+kQ4DpgGvDHwN51tbER8X91o/9yV9ABIuJ3kh7h452WhfqNiEOG0a+ofT9fFhG/HGr81HgzvlqvDT1KUwdlz3dR2+Nc/zgVOLBIY1kgH8zmdR1wMvBV4B+yUQZvgWxpMJstwKRO9JuZBXwZ+KGksZLGUtsSAdhP0v4lLGPE8pq9Wo2uL/6Q2ubqPoOGDw7D69nzldQ2rwd7v1hrHA38KfCtiPhoX4KkbzUZf0KTYZuy1+3uF+AYYAzwYoPav1P743NwCcsZkRz2LhMROyVtAr40qPQXg96vAX4LHB0RN7ehlc9nzx8dp5b0OWBmk/G/Junguu/s46jttPtZh/qF2ib84J14U4G/B74HPNOm5Y4IDnt3WgZ8X9LVQD9wCvCJNWr2R+EyYLmkzwP3Ult7HgycALxYv4OtCUk6t8HwjdROBvotcGPdobYrqe3lbmQbsFLS9dS2TP6W2v+vH5bRr6SNwLMRMfiP3kci4hVqO/vqp9v1deN/IuK/mk2bAoe9O11HbXP0r6mtYR+gdvjryfqRIuI+SadQ2+O9CBgFbAb+G7hzGMvZC1jeYPi9EXGupOnAP1H7nv06tTXn68C/NJjmEWAVcCO1nXlrgNMjYn1J/X6Guh2Etvvkn6UyS4P3xpslwmE3S4TDbpYIh90sER3dGz9+/Pjo7e3t5CLNkrJ+/Xq2bdvW8IKAQmGXdAa1ixv2Bn4cEQvyxu/t7aW/v7/IIs0sR19fX9Nay5vxkvamdrz1TGqnKc6UdEyr8zOz9irynX0qsC4iXomID6id9TW9nLbMrGxFwj6JT/4KyEY+vsLpI5LmSuqX1D8wMFBgcWZWRNv3xkfEwojoi4i+np6edi/OzJooEvZNwKF17w/h48sZzazLFAn708BkSYdL2ge4AFhRTltmVraWD71lv+91GbWrnfYGbo+I50vrzMxKVeg4e0Q8BDxUUi9m1kY+XdYsEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslotAtmyWtB94CdgI7IqKvjKbMrHyFwp45JSK2lTAfM2sjb8abJaJo2AN4VNIzkuY2GkHSXEn9kvoHBgYKLs7MWlU07CdGxLHAmcClkk4aPEJELIyIvojo6+npKbg4M2tVobBHxKbseStwHzC1jKbMrHwth13SaEljdr0GTgPWltWYmZWryN74CcB9knbN5+6IeLiUrvYwN9xwQ259/vz5ufWZM2fm1u++++7d7qkbPProo7n1008/Pbd+9tln59YfeOCB3e5pT9Zy2CPiFeDLJfZiZm3kQ29miXDYzRLhsJslwmE3S4TDbpaIMi6EsSG8++67haYfM2ZMSZ10l3Xr1hWafqhDd6tWrWpaO/bYYwsteyTymt0sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4SPs3fA8uXLC00/ZcqUkjrpLi+//HKh6UeNGpVb31PPT2iV1+xmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSJ8nL0E27dvz62/9957heY/ku+kk3eOwZ133llo3hMnTsytT548udD89zRes5slwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmifBx9hKsXZt/W/pXX3210PyPPPLIQtO30/vvv59bv+2225rWtm7dWmjZ++67b6HpUzPkml3S7ZK2SlpbN+wASSslvZQ9j2tvm2ZW1HA2438CnDFo2DzgsYiYDDyWvTezLjZk2CPiCeCNQYOnA4uz14uBGSX3ZWYla3UH3YSI2Jy9fg2Y0GxESXMl9UvqHxgYaHFxZlZU4b3xERFA5NQXRkRfRPSN5As6zEa6VsO+RdJEgOy52G5VM2u7VsO+ApidvZ4N3F9OO2bWLkMeZ5e0FDgZGC9pI3ANsAC4R9IcYANwXjubTF03X5d91VVX5dZXrlzZtmWff/75bZv3nmjIsEfEzCalr5fci5m1kU+XNUuEw26WCIfdLBEOu1kiHHazRPgS1xIU/Unkbnbdddfl1m+99da2LXvs2LG59Ysuuqhty94Tec1ulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCx9lLsHPnzqpbaNlQ5wgsWLAgt75jx44y2/mE448/Prd+0EEHtW3ZeyKv2c0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRPg4ewmmTJmSW99///1z69u3b8+tb9iwIbd+1FFHNa1t2rQpd9qLL744tz7ULZnbqbe3t7Jl74m8ZjdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuHj7CW45JJLcutPPfVUbn3JkiW59WuuuSa3Pm3atKa1K664Infad955J7feTnvtlb+umTFjRoc6ScOQa3ZJt0vaKmlt3bBrJW2StDp7nNXeNs2sqOFsxv8EOKPB8FsiYkr2eKjctsysbEOGPSKeAN7oQC9m1kZFdtBdJum5bDN/XLORJM2V1C+pf2BgoMDizKyIVsN+K/BFYAqwGbip2YgRsTAi+iKir6enp8XFmVlRLYU9IrZExM6I+ANwGzC13LbMrGwthV3SxLq33wDWNhvXzLrDkMfZJS0FTgbGS9oIXAOcLGkKEMB64Ltt7HHEmzVrVm79zTffzK0vX748t37PPffsdk+7jBo1Krc+ffr03PqyZctaXvZxxx2XWz/ttNNanrd92pBhj4iZDQYvakMvZtZGPl3WLBEOu1kiHHazRDjsZolw2M0S4UtcO+DUU08tVF+0KP/gx4oVK5rWDjvssNxpL7/88tz6gw8+mFsvcuht6lSfi9VJXrObJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZonwcfYRYM6cOYXqRdxxxx1tm/e4cU1/zczawGt2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRPs5uuc4555zc+urVq3PrRxxxRNPavHnzWurJWuM1u1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WiOHcsvlQYAkwgdotmhdGxI8kHQD8DOildtvm8yLid+1r1aqwdu3aQtPn3RJ69OjRheZtu2c4a/YdwJURcQzwZ8Clko4B5gGPRcRk4LHsvZl1qSHDHhGbI2JV9vot4AVgEjAdWJyNthiY0a4mzay43frOLqkX+ArwK2BCRGzOSq9R28w3sy417LBL2g+4F7giIrbX1yIiqH2fbzTdXEn9kvoHBgYKNWtmrRtW2CV9llrQ74qIn2eDt0iamNUnAlsbTRsRCyOiLyL6enp6yujZzFowZNglCVgEvBARN9eVVgCzs9ezgfvLb8/MyjKcS1xPAGYBayTtup5xPrAAuEfSHGADcF57WrQqHXjggYWmP+88/7foFkOGPSKeBNSk/PVy2zGzdvEZdGaJcNjNEuGwmyXCYTdLhMNulgiH3SwR/ilpy/Xqq68Wmj7vElfrLK/ZzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNE+Di75dq6teEPENkI5DW7WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIH2e3XGPGjKm6BSuJ1+xmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSKGPM4u6VBgCTABCGBhRPxI0rXAd4CBbNT5EfFQuxq1aixdujS3fuGFF3aoEytqOCfV7ACujIhVksYAz0hamdVuiYh/bF97ZlaWIcMeEZuBzdnrtyS9AExqd2NmVq7d+s4uqRf4CvCrbNBlkp6TdLukcU2mmSupX1L/wMBAo1HMrAOGHXZJ+wH3AldExHbgVuCLwBRqa/6bGk0XEQsjoi8i+np6ekpo2cxaMaywS/ostaDfFRE/B4iILRGxMyL+ANwGTG1fm2ZW1JBhlyRgEfBCRNxcN3xi3WjfANaW356ZlWU4e+NPAGYBayStzobNB2ZKmkLtcNx64Ltt6dAqNWlS/r7Yxx9/vDONWGHD2Rv/JKAGJR9TNxtBfAadWSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4QionMLkwaADXWDxgPbOtbA7unW3rq1L3BvrSqzt8MiouHvv3U07J9auNQfEX2VNZCjW3vr1r7AvbWqU715M94sEQ67WSKqDvvCipefp1t769a+wL21qiO9Vfqd3cw6p+o1u5l1iMNulohKwi7pDEn/K2mdpHlV9NCMpPWS1khaLam/4l5ul7RV0tq6YQdIWinppey54T32KurtWkmbss9utaSzKurtUEm/kPRrSc9LujwbXulnl9NXRz63jn9nl7Q38CIwDdgIPA3MjIhfd7SRJiStB/oiovITMCSdBLwNLImIL2XDbgTeiIgF2R/KcRFxdZf0di3wdtW38c7uVjSx/jbjwAzg21T42eX0dR4d+NyqWLNPBdZFxCsR8QGwDJheQR9dLyKeAN4YNHg6sDh7vZjaf5aOa9JbV4iIzRGxKnv9FrDrNuOVfnY5fXVEFWGfBPym7v1Guut+7wE8KukZSXOrbqaBCRGxOXv9GjChymYaGPI23p006DbjXfPZtXL786K8g+7TToyIY4EzgUuzzdWuFLXvYN107HRYt/HulAa3Gf9IlZ9dq7c/L6qKsG8CDq17f0g2rCtExKbseStwH913K+otu+6gmz1vrbifj3TTbbwb3WacLvjsqrz9eRVhfxqYLOlwSfsAFwArKujjUySNznacIGk0cBrddyvqFcDs7PVs4P4Ke/mEbrmNd7PbjFPxZ1f57c8jouMP4Cxqe+RfBn5QRQ9N+voC8Gz2eL7q3oCl1DbrPqS2b2MOcCDwGPAS8B/AAV3U20+BNcBz1II1saLeTqS2if4csDp7nFX1Z5fTV0c+N58ua5YI76AzS4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLx/4xPFEosK9qBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 42\n",
    "\n",
    "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
    "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rn_-9OsPYnDp"
   },
   "source": [
    "## Build a Model\n",
    "\n",
    "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "EgMgJJynMbVY",
    "outputId": "f09b342e-ca92-4cce-cdb7-22e7a1057b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "Softmax (Dense)              (None, 10)                13530     \n",
      "=================================================================\n",
      "Total params: 13,610\n",
      "Trainable params: 13,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Create a model.\n",
    "model =  tf.keras.Sequential([\n",
    "    \n",
    "        tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
    "                               strides=2, activation='relu', name='Conv1'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLzXnZT1YvS6"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LTNN0ANGgA36",
    "outputId": "0885851e-51f8-47e7-96d7-6c4d53713713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3098 - accuracy: 0.9120 - val_loss: 0.1723 - val_accuracy: 0.9489\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.1511 - accuracy: 0.9569 - val_loss: 0.1145 - val_accuracy: 0.9667\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1103 - accuracy: 0.9680 - val_loss: 0.0939 - val_accuracy: 0.9720\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0901 - accuracy: 0.9737 - val_loss: 0.0895 - val_accuracy: 0.9739\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0780 - accuracy: 0.9763 - val_loss: 0.0787 - val_accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Configure the model for training.\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# EXERCISE: Train the model.\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size = 16,\n",
    "                    epochs = epochs,\n",
    "                    validation_data= [test_images, test_labels],\n",
    "                    verbose = 1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Er_vrDhf4qu5"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gMD387B93f2g",
    "outputId": "db07f75d-4468-4e0d-f4e7-edca33f3a4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/sample - loss: 0.0787 - accuracy: 0.9758\n",
      "loss: 0.0787\n",
      "accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Evaluate the model on the test images.\n",
    "results_eval = model.evaluate(test_images, test_labels)\n",
    "\n",
    "for metric, value in zip(model.metrics_names, results_eval):\n",
    "    print(metric + ': {:.3}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGfmT8M1Yx5y"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/qx/wrjdfy9d1sq4_104x_y4g7kr0000gn/T'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempfile.gettempdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "9uFDoDW_7HX6",
    "outputId": "f3bc22bb-00dd-4a13-dd84-b0e4c466b6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x14b582bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x14b582bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /Users/ZRC/miniconda3/envs/tryit/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1809: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /var/folders/qx/wrjdfy9d1sq4_104x_y4g7kr0000gn/T/1/assets\n",
      "\n",
      "export_path = /var/folders/qx/wrjdfy9d1sq4_104x_y4g7kr0000gn/T/1\n",
      "total 152\n",
      "drwxr-xr-x  2 ZRC  staff     64 Feb 21 22:17 \u001b[1m\u001b[36massets\u001b[m\u001b[m\n",
      "-rw-r--r--  1 ZRC  staff  74809 Feb 21 22:17 saved_model.pb\n",
      "drwxr-xr-x  4 ZRC  staff    128 Feb 21 22:17 \u001b[1m\u001b[36mvariables\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = tempfile.gettempdir()\n",
    "\n",
    "version = 1\n",
    "\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "\n",
    "if os.path.isdir(export_path):\n",
    "    print('\\nAlready saved a model, cleaning up\\n')\n",
    "    !rm -r {export_path}\n",
    "\n",
    "model.save(export_path, save_format=\"tf\")\n",
    "\n",
    "print('\\nexport_path = {}'.format(export_path))\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KziE3e9tY-hH"
   },
   "source": [
    "## Examine Your Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LU4GDF_aYtfQ",
    "outputId": "b18e83c5-5970-40a8-d941-e64f3bf76c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['Conv1_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: serving_default_Conv1_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['Softmax'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /Users/ZRC/miniconda3/envs/tryit/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1809: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsDTdBGHZAzo"
   },
   "source": [
    "## Add TensorFlow Serving Distribution URI as a Package Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "EWg9X2QHlbGS",
    "outputId": "1048b8f3-1f9c-4fc4-cae1-c654f36ae32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tee: /etc/apt/sources.list.d/tensorflow-serving.list: No such file or directory\n",
      "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
      "Unable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk1.8.0_73.jdk/Contents/Home/bin/apt\" (-1)\n"
     ]
    }
   ],
   "source": [
    "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
    "# You would instead do:\n",
    "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "\n",
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "!apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l5XkzqNZNBU"
   },
   "source": [
    "## Install TensorFlow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ygwa9AgRloYy",
    "outputId": "797d062d-e98e-424e-fe86-631192b0b9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd_PobAKZWW8"
   },
   "source": [
    "## Run the TensorFlow Model Server\n",
    "\n",
    "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
    "\n",
    "* `rest_api_port`: Use port `8501` for your requests.\n",
    "\n",
    "\n",
    "* `model_name`: Use `digits_model` as your model name. \n",
    "\n",
    "\n",
    "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUgp3vUdU5GS"
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/qx/wrjdfy9d1sq4_104x_y4g7kr0000gn/T'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- -p 8501:8501 : Publishing the container’s port 8501 (where TF Serving responds to REST API requests) to the host’s port 8501\n",
    "- --mount type=bind,source=/tmp/resnet,target=/models/resnet : Mounting the host’s local directory (/tmp/resnet) on the container (/models/resnet) so TF Serving can read the model from inside the container.\n",
    "- -e MODEL_NAME=digits_model : Telling TensorFlow Serving to load the model named “digits_model”\n",
    "- -t tensorflow/serving : Running a Docker container based on the serving image “tensorflow/serving”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid argument \"ount\" for \"-m, --memory\" flag: invalid size: 'ount'\n",
      "See 'docker run --help'.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\ndocker run -p 8501:8501 \\\\\\n  -mount type=bind, source=\"${MODEL_DIR}\",target=/models/my_model \\\\\\n  -e MODEL_NAME=digits_model -t tensorflow/serving\\n'' returned non-zero exit status 125.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2b07364afead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\ndocker run -p 8501:8501 \\\\\\n  -mount type=bind, source=\"${MODEL_DIR}\",target=/models/my_model \\\\\\n  -e MODEL_NAME=digits_model -t tensorflow/serving\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tryit/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tryit/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/ZRC/miniconda3/envs/tryit/lib/python3.6/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tryit/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tryit/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\ndocker run -p 8501:8501 \\\\\\n  -mount type=bind, source=\"${MODEL_DIR}\",target=/models/my_model \\\\\\n  -e MODEL_NAME=digits_model -t tensorflow/serving\\n'' returned non-zero exit status 125."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "docker run -p 8501:8501 \\\n",
    "  --mount type=bind, source=\"${MODEL_DIR}\",target=/models/my_model \\\n",
    "  -e MODEL_NAME=digits_model -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kJDhHNJVnaLN",
    "outputId": "ded8b2b4-40b2-48ec-eba5-1dc99a4af186"
   },
   "outputs": [],
   "source": [
    "# # EXERCISE: Fill in the missing code below.\n",
    "# %%bash --bg \n",
    "# nohup tensorflow_model_server \\\n",
    "#   --rest_api_port=8501 \\\n",
    "#   --model_name=digits_model \\\n",
    "#   --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IxbeiOCUUs2z",
    "outputId": "d2bc13e1-167a-49c6-d19f-41dd401a8da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: server.log: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mUrIWVRZdNu"
   },
   "source": [
    "## Create JSON Object with Test Images\n",
    "\n",
    "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dsD7KQG1m-R"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Create JSON Object\n",
    "data = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRdyPl4CZ5CU"
   },
   "source": [
    "## Make Inference Request\n",
    "\n",
    "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGvFyuIzW6n6"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Fill in the code below\n",
    "headers = # YOUR CODE HERE\n",
    "json_response = # YOUR CODE HERE\n",
    "    \n",
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FtrFMts_ackX"
   },
   "source": [
    "## Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "BxQzj34aiDz1",
    "outputId": "955b05c7-88ec-4200-cde8-2dac283ebcde"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
    "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TFServing_Week1_Exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
